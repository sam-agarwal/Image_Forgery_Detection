# -*- coding: utf-8 -*-
"""EE769_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RmWY_ESSLH8GX0ZR0lg7DrZDZZ_bYko4
"""

import matplotlib.pyplot as plt
import numpy as np
import os
from sklearn.model_selection import train_test_split
import seaborn as sns
import sys
from sklearn.metrics import log_loss, accuracy_score, confusion_matrix
import cv2
import glob
from google.colab.patches import cv2_imshow
from sklearn.metrics import classification_report

from google.colab import drive
drive.mount('/content/drive')

"""## EDA and Data Preprocessing"""

path = "/content/drive/MyDrive/training"
fake_path = path + '/fake/*.*'
pristine_path = path + '/pristine/*.*'

"""Pristine Image Example"""

ex1_path = '/content/drive/MyDrive/training/pristine/03a6cc0eef8dd6bec2cd71ec8b1546ab.png'
p1= cv2.imread(ex1_path)
cv2_imshow(p1)

"""Fake Image Example"""

ex2_path = '/content/drive/MyDrive/training/fake/010543abfbd0db1e9aa1b24604336e0c.png'
f1 = cv2.imread(ex2_path)
cv2_imshow(f1)

ex2_mask_path = '/content/drive/MyDrive/training/fake/010543abfbd0db1e9aa1b24604336e0c.mask.png'
f2 = cv2.imread(ex2_mask_path)
cv2_imshow(f2)

"""Seperating fake images and masks"""

pristine_images = []
data = []
fake_images = []
fake_images_mask = []
number_1channel = 0
number_4channel = 0
for file in glob.glob(pristine_path):
  img = cv2.imread(file)
  #print(img.shape)
  #print(img.shape)
  
  if(len(img.shape)==3 and img.shape[2]==3):
     pristine_images.append(img)
     data.append(img)

fake_images = []
fake_images_mask = []

for file in glob.glob(fake_path):
  file_name = file.split('/')[-1]
  if(len(file_name.split('.'))!=3):
    img = cv2.imread(file)
    fake_images.append(img)
    mask_path = path+'/fake/'+file_name.split('.')[0]+'.mask.png'
    img_mask = cv2.imread(mask_path,0)
    fake_images_mask.append(img_mask)

print(fake_images_mask[0].shape)

print(len(fake_images))
print(len(fake_images_mask))

"""Verifying here whether the arrays are in sync or not"""

cv2_imshow(fake_images[100])

cv2_imshow(fake_images_mask[100])

for i in range(20):
    index=np.random.randint(0, len(pristine_images))  #printing shapes of random pristine images
    print(pristine_images[index].shape)

for i in range(20):
    index=np.random.randint(0, len(fake_images))  #printing shapes of random fake images
    print(fake_images[index].shape)

"""Train Test Split"""

# splitting images and mask for training and testing. patches will be extracted later

label_pristine = [0]*len(pristine_images)

X_train_p, X_test_p, Y_train_p, Y_test_p = train_test_split(pristine_images,label_pristine,test_size=0.25)

testing_indices_f = np.random.randint(450,size=113)

np_fake_images = np.array(fake_images)
np_fake_images_mask = np.array(fake_images_mask)

X_test_f = np_fake_images[testing_indices_f]
X_test_m = np_fake_images_mask[testing_indices_f]
Y_test_f = [1]*len(X_test_f)

X_train_f = np.delete(np_fake_images,testing_indices_f).copy()
X_train_m = np.delete(np_fake_images_mask,testing_indices_f).copy()
Y_train_f = [1]*len(X_train_f)

print(X_test_f.shape)
#print(X_test_m.shape)
print(X_train_f.shape)
print(X_train_m.shape)

cv2_imshow(X_train_f[11])

cv2_imshow(X_train_m[11])

"""##Feature Extraction"""

# removing noise from the masks and converting it to binary from grayscale
binary_masks = []
for masks in X_train_m:
  blurred = cv2.GaussianBlur(masks,(5,5),0)
  ret,th = cv2.threshold(blurred,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)
  binary_masks.append(th)

"""Mask without thresholding and in Grayscale"""

cv2_imshow(X_train_m[11])

"""Mask with thresholding and in binary"""

cv2_imshow(binary_masks[11])

pixels_count = []
for i in binary_masks:
  pixels_count.append(np.count_nonzero(~i)) #counting number of pixels which are zero i.e counting no of pixels which form mask of fake part

plt.plot(sorted(pixels_count))
plt.xlabel("Number of binary masks")
plt.ylabel("Number of zero pixels")
plt.show()

def valid_patch(mask,threshold,kernel_size):
  count = 0
  for i in range(mask.shape[0]):
    for j in range(mask.shape[1]):
      if (mask[i,j]==255):
        count+=1
  return (count > threshold)  and ((kernel_size*kernel_size - count) > threshold )

def fake_patches(img,mask):
  threshold = 1600
  kernel_size = 64
  stride = 32
  patches = []
  for i in range(0,img.shape[0]-kernel_size+1,stride):
    for j in range(0, img.shape[1]-kernel_size+1, stride):
      if(valid_patch(mask[i:i+kernel_size,j:j+kernel_size],threshold,kernel_size)):
        patches.append(img[i:i+kernel_size,j:j+kernel_size])

  return patches

def pristine_patches(img,kernel,n,stride=64):

  patches=[]
  x_range = np.arange(0,img.shape[0]-kernel+1,stride)
  y_range = np.arange(0,img.shape[1]-kernel+1,stride)
  x_list = x_range[np.random.randint(len(x_range),size=n)]
  y_list = y_range[np.random.randint(len(y_range),size=n)]

  for i in range(n):
    patches.append(img[x_list[i]:x_list[i]+kernel,y_list[i]:y_list[i]+kernel])

  return patches

a= fake_patches(X_train_f[20],binary_masks[20])

len(a)

print(a[0].shape)

#resize_sample = cv2.resize(a[10],(500,500))
#cv2_imshow(resize_sample)
cv2_imshow(a[2])

"""Patches for few Images

####Fake Image Patches
"""

cv2_imshow(X_train_f[10])

cv2_imshow(binary_masks[10])

p1= fake_patches(X_train_f[10],binary_masks[10])

resize_sample = cv2.resize(p1[0],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p1[1],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p1[5],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p1[6],(500,500))
cv2_imshow(resize_sample)

cv2_imshow(X_train_f[50])

cv2_imshow(binary_masks[50])

p2= fake_patches(X_train_f[50],binary_masks[50])

resize_sample = cv2.resize(p2[0],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p2[1],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p2[2],(500,500))
cv2_imshow(resize_sample)

cv2_imshow(X_train_f[100])

cv2_imshow(binary_masks[100])

p3= fake_patches(X_train_f[100],binary_masks[100])

resize_sample = cv2.resize(p3[0],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p3[5],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p3[8],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p3[14],(500,500))
cv2_imshow(resize_sample)

"""#### Pristine Image Patches"""

cv2_imshow(X_train_p[10])

p4 = pristine_patches(X_train_p[10],64,4)

resize_sample = cv2.resize(p4[0],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p4[1],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p4[2],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p4[3],(500,500))
cv2_imshow(resize_sample)

cv2_imshow(X_train_p[50])

p5 = pristine_patches(X_train_p[50],64,4)

resize_sample = cv2.resize(p5[0],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p5[1],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p5[2],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p5[3],(500,500))
cv2_imshow(resize_sample)



cv2_imshow(X_train_p[150])

p6 = pristine_patches(X_train_p[150],64,4)

resize_sample = cv2.resize(p6[0],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p6[1],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p6[2],(500,500))
cv2_imshow(resize_sample)
resize_sample = cv2.resize(p6[3],(500,500))
cv2_imshow(resize_sample)

"""###Extracting Patches """

fake_samples=[]
for fake, mask in zip(X_train_f, binary_masks):
    img_patches=fake_patches(fake, mask)
    for patch in img_patches:
        fake_samples.append(patch)
    print('done')

np.save("fake_images_patches_64.npy", np.array(fake_samples))

"""Fake Image Patches augmentation obtained by 64 strides"""

import imgaug as ia
import imgaug.augmenters as iaa

#Horizontal Flip
hflip= iaa.Fliplr(p=1.0)
input_hf= hflip.augment_image(fake_samples[13])
#Vertical Flip
vflip= iaa.Flipud(p=1.0) 
input_vf= vflip.augment_image(fake_samples[13])
crop1 = iaa.Crop(percent=(0, 0.3)) 
input_crop1 = crop1.augment_image(fake_samples[13])

cv2_imshow(fake_samples[13])
cv2_imshow(input_hf)
cv2_imshow(input_vf)
cv2_imshow(input_crop1)

fake_samples_aug = []

for sample in fake_samples: 
  hflip= iaa.Fliplr(p=1.0)
  vflip= iaa.Flipud(p=1.0)
  crop = iaa.Crop(percent=(0, 0.25))

  sample_hf= hflip.augment_image(sample)
  sample_vf = vflip.augment_image(sample)
  sample_crop = crop.augment_image(sample)

  fake_samples_aug.append(sample)
  fake_samples_aug.append(sample_hf)
  fake_samples_aug.append(sample_vf)
  fake_samples_aug.append(sample_crop)

print(len(fake_samples_aug))

np.save("fake_images_patches_augmented_64.npy", np.array(fake_samples_aug))

print(len(fake_samples))

print(fake_samples[0].shape)

"""Patches from pristine images"""

patches = pristine_patches(pristine_images[0],64,6)
for patch in patches:
  resized = cv2.resize(patch, (300,300))
  cv2_imshow(resized)

pristine_samples= []

counter_2 = 0

for img in X_train_p:
  patches = pristine_patches(img,64,10)
  for j in patches:
    pristine_samples.append(j)
  #print(counter_2)
  #counter_2 +=1

print(len(X_train_p))
print(len(pristine_samples))
print(pristine_samples[0].shape)

np.save("pristine_images_patches_64.npy", np.array(pristine_samples))

cv2_imshow(pristine_samples[100])

"""Feature Extraction for testing Data"""

# removing noise from the masks and converting it to binary from grayscale
binary_masks_2 = []
for masks in X_test_m:
  blurred = cv2.GaussianBlur(masks,(5,5),0)
  ret,th = cv2.threshold(blurred,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)
  binary_masks_2.append(th)

fake_samples_test=[]
for fake, mask in zip(X_test_f, binary_masks_2):
    img_patches=fake_patches(fake, mask)
    for patch in img_patches:
        fake_samples_test.append(patch)
    print('done')

np.save("test_fake_images_patches_32.npy", np.array(fake_samples_test))

print(len(fake_samples_test))

pristine_samples= []

#counter_2 = 0

for img in X_test_p:
  patches = pristine_patches(img,64,10)
  for j in patches:
    pristine_samples.append(j)
  #print(counter_2)
  #counter_2 +=1

np.save("test_pristine_images_patches.npy", np.array(pristine_samples))

print(len(pristine_samples))

"""# Model Training

## Data Loading
"""

fake_32 = np.load('/content/drive/MyDrive/data/fake_images_patches_32.npy')
pristine = np.load('/content/drive/MyDrive/data/pristine_images_patches_64.npy')
print(pristine.shape)
print(fake_32.shape)

X3 = np.concatenate((pristine,fake_32))
Y3 = np.array([0]*len(pristine) + [1]*len(fake_32))

x3_train, x3_cv, y3_train, y3_cv = train_test_split(X3, Y3, test_size=0.3, stratify = Y3)



X1 = np.concatenate((pristine,fake_32))
Y1 = np.array([0]*len(pristine) + [1]*len(fake_32))

print(X1.shape)
print(Y1.shape)

fake_64 = np.load('/content/drive/MyDrive/data/fake_images_patches_augmented_64.npy')
test_fake = np.load('/content/drive/MyDrive/data/test_fake_images_patches_32.npy')
test_pristine = np.load('/content/drive/MyDrive/data/test_pristine_images_patches.npy')

X2 = np.concatenate((pristine,fake_64))
Y2 = np.array([0]*len(pristine) + [1]*len(fake_64))

print(X2.shape)
print(Y2.shape)

x_test = np.concatenate((test_pristine,test_fake))
y_test = np.array([0]*len(test_pristine) + [1]*len(test_fake))
x_test = x_test/255.0

print(x_test.shape)
print(y_test.shape)

"""Splitting data into training and validation"""

x1_train, x1_cv, y1_train, y1_cv = train_test_split(X1, Y1, test_size=0.3, stratify = Y1)

print(x1_train.shape)
print(y1_train.shape)
print(x1_cv.shape)
print(y1_cv.shape)

# normalizing input data. good for training cnn data
x1_train = x1_train/255.0
x1_cv = x1_cv/255.0
#print(x1_train[0])

x2_train, x2_cv, y2_train, y2_cv = train_test_split(X2, Y2, test_size=0.3, stratify = Y2)
print(x2_train.shape)
print(y2_train.shape)
print(x2_cv.shape)
print(y2_cv.shape)

# normalizing input data. good for training cnn data
x2_train = x2_train/255.0
x2_cv = x2_cv/255.0
#print(x1_train[0])

"""### Metrics for Evaluation"""

def gen_confusion_matrix(Y_test, Y_pred):
  CM = confusion_matrix(Y_test, Y_pred)

  PM = CM/np.sum(CM,axis=0)
  RM = np.transpose((np.transpose(CM))/(np.sum(CM, axis=1)))

  labels = [0,1]
  map = sns.light_palette('red')

  plt.figure(figsize=(12,4))
  plt.subplot(1, 2, 1)
  sns.heatmap(PM, annot=True, cmap=map, fmt=".3f", xticklabels=labels, yticklabels=labels)
  plt.xlabel('Predicted Class')
  plt.ylabel('Original Class')
  plt.title("Precision matrix")
  
 # plt.subplot(1,2,2)
  #sns.heatmap(RM, annot=True, cmap=map, fmt=".3f", xticklabels=labels, yticklabels=labels)
  #plt.xlabel('Predicted Class')
  #plt.ylabel('Original Class')
  #plt.title("Recall matrix")

  plt.show()

true = [0,1,0,1]
pred = [1,0,0,0]
gen_confusion_matrix(true,pred)

"""## Loading Model and Testing

### Random Model
"""

# will use the validation data for testing in this model as no validation required
y_pred_prob = np.zeros((len(y1_cv),2))
for i in range(len(y1_cv)):
    rand_probs = np.random.rand(1,2) #predicting probability for different classes such that sum is 1.  predicting it for all elements of testing data
    y_pred_prob[i] = ((rand_probs/sum(sum(rand_probs)))[0])

#print(y_pred_prob)
y_pred = np.argmax(y_pred_prob,axis = 1)
gen_confusion_matrix(y1_cv,y_pred)
# y_pred is prediction and  y_cv contains true value 

# print log loss and accuracy

"""### Resnet 50"""

import keras
from keras.models import  Model, load_model, Sequential
from keras.layers import Dense, Flatten
from tensorflow.keras.applications.resnet50 import ResNet50
from keras import optimizers

resnet_model=ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))
#output = resnet_model.layers[-1].output
#output1 = keras.layers.Flatten()(output)
#resnet_model = Model(resnet_model.input, outputs=output1)

for layer in resnet_model.layers[:171]:
    layer.trainable = False
  
resnet_model.summary()

model_res=Sequential()
model_res.add(resnet_model)
model_res.add(Flatten(input_shape=(2, 2, 2048)))
model_res.add(Dense(64, activation = 'relu'))
model_res.add(layers.Dropout(0.5))
model_res.add(Dense(32, activation = 'relu'))
model_res.add(Dense(16, activation = 'relu'))
model_res.add(Dense(1, activation = 'sigmoid'))

  
model_res.summary()

model_res.compile(loss='binary_crossentropy',  optimizer=optimizers.Adam(lr= 1e-3),  metrics=['accuracy'])

"""Training Resnet50"""

history2 = model_res.fit(x3_train,y3_train,epochs = 50, batch_size=25, validation_data = (x3_cv,y3_cv))

plt.plot(history2.history['accuracy'], label='accuracy')
plt.plot(history2.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])

model_res.evaluate(x_test*255, y_test, verbose=0)

y_pred = np.where(model_res.predict(x_test*255)>0.8, 1,0)

gen_confusion_matrix(y_test,y_pred)

print(classification_report(y_test, y_pred))

model_res.save('resnet50_1.h5')

"""## VGG16"""

import keras.applications 
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input

## Loading VGG16 model
base_model = VGG16(weights="imagenet", include_top=False, input_shape=(64, 64, 3))
#base_model.trainable = False ## Not trainable weights
for layer in base_model.layers[:17]:
    layer.trainable = False
base_model.summary()

from tensorflow.keras import layers, models

flatten_layer = layers.Flatten()
dense_layer_1 = layers.Dense(50, activation='relu')
dense_layer_2 = layers.Dense(20, activation='relu')
drop = layers.Dropout(0.2)
prediction_layer = layers.Dense(1, activation='sigmoid')


model = models.Sequential([
    base_model,
    flatten_layer,
    dense_layer_1,
    #drop,
    dense_layer_2,
    prediction_layer
])

model.summary()

from tensorflow.keras.callbacks import EarlyStopping
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy'],
)


es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)
history = model.fit(x3_train, y3_train, epochs=50, validation_data=(x3_cv, y3_cv), batch_size=32)

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])

model.evaluate(x_test*255, y_test, verbose=0)

y_pred = np.where(model.predict(x_test*255)>0.5, 1,0)

gen_confusion_matrix(y_test,y_pred)

print(classification_report(y_test, y_pred))

